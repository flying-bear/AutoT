{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение коллокаций\n",
    "\n",
    "Коллокации — устойчивые n-граммы (обычно биграммы; есть множество определений, мы пока будем использовать интуитивное представление об устойчивом выражении).\n",
    "\n",
    "Сначала давайте научимся доставать из текста биграммы и заодно фильтровать их по морфологическим характеристикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я', 'ненавижу', 'программировать', 'Убейте', 'меня', 'плз111']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Я ненавижу программировать! Убейте меня плз111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    lemmas = [m.parse(t)[0].normal_form for t in tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я', 'ненавидеть', 'программировать', 'убить', 'я', 'плз111']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('Я ненавижу программировать! Убейте меня плз111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONJ', 'NPRO', 'NOUN']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.parse(t)[0].tag.POS for t in ['а', 'я', 'дурак']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(tokens, n=2, patterns=None):\n",
    "    \"\"\"\n",
    "    Если patterns не None, давайте проверять, что части речи биграммы есть в patterns.\n",
    "    Например, patterns = (['ADJF', 'NOUN'], ['CONJ', 'NPRO', 'NOUN')\n",
    "    Подумаем о том, хотим ли мы склеивать два слова из разных предложений.\n",
    "    Можно использовать itertools.islice\n",
    "    \"\"\"\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens) - (n - 1)):\n",
    "        ngram = tokens[i:i+n]\n",
    "        tags = [m.parse(t)[0].tag.POS for t in ngram]\n",
    "        if patterns is not None:\n",
    "            if tags in patterns:\n",
    "                ngrams.append(ngram)\n",
    "        else:\n",
    "            ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['красивый', 'девочка']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams(normalize('Красивая девочка дурочка'), n=2, patterns=[['ADJF', 'NOUN']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем на каком-нибудь тексте (давайте считать, что каждая строчка = предложение):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Кречет (лат. Falco rusticolus) — птица из отряда соколообразных семейства соколиных.\n",
    "Самый крупный из соколов. \n",
    "Масса самца чуть больше 1 кг, самки — до 2 кг. \n",
    "Окраска сибирского кречета светлая (светлее лапландских кречетов), но изменчивая: от буровато-серой до почти белой сверху; брюшная сторона беловатая с темным рисунком. \n",
    "Темная полоска у разреза рта («усы») почти незаметна. \n",
    "На надклювье, как у всех соколов, характерный зубец. \n",
    "Лапы жёлтые. \n",
    "Скорость в полёте высокая, после нескольких взмахов птица быстро несётся вперёд, не парит. \n",
    "Сидящий кречет держится прямо.\n",
    "Кречет похож на сапсана, но крупнее и имеет относительно более длинный хвост. \n",
    "Голос также похож на голос сапсана, но грубее и ниже: хриплое «кьяк-кьяк-кьяк» или протяжное «кеек-кеек-кеек». \n",
    "Весной может издавать довольно тихую и высокую трель. \n",
    "Южный горный подвид — алтайский кречет, которого многие специалисты считают подвидом или морфой балобана, — отличается более однообразной темной окраской.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['кречет', 'лата'],\n",
       " ['лата', 'falco'],\n",
       " ['falco', 'rusticolus'],\n",
       " ['rusticolus', 'птица'],\n",
       " ['птица', 'из'],\n",
       " ['из', 'отряд'],\n",
       " ['отряд', 'соколообразный'],\n",
       " ['соколообразный', 'семейство'],\n",
       " ['семейство', 'соколиный'],\n",
       " ['соколиный', 'самый'],\n",
       " ['самый', 'крупный'],\n",
       " ['крупный', 'из'],\n",
       " ['из', 'соколов'],\n",
       " ['соколов', 'масса'],\n",
       " ['масса', 'самец'],\n",
       " ['самец', 'чуть'],\n",
       " ['чуть', 'большой'],\n",
       " ['большой', '1'],\n",
       " ['1', 'килограмм'],\n",
       " ['килограмм', 'самка'],\n",
       " ['самка', 'до'],\n",
       " ['до', '2'],\n",
       " ['2', 'килограмм'],\n",
       " ['килограмм', 'окраска'],\n",
       " ['окраска', 'сибирский'],\n",
       " ['сибирский', 'кречет'],\n",
       " ['кречет', 'светлый'],\n",
       " ['светлый', 'светлый'],\n",
       " ['светлый', 'лапландский'],\n",
       " ['лапландский', 'кречетовый'],\n",
       " ['кречетовый', 'но'],\n",
       " ['но', 'изменчивый'],\n",
       " ['изменчивый', 'от'],\n",
       " ['от', 'буроватый'],\n",
       " ['буроватый', 'сера'],\n",
       " ['сера', 'до'],\n",
       " ['до', 'почти'],\n",
       " ['почти', 'бела'],\n",
       " ['бела', 'сверху'],\n",
       " ['сверху', 'брюшной'],\n",
       " ['брюшной', 'сторона'],\n",
       " ['сторона', 'беловатый'],\n",
       " ['беловатый', 'с'],\n",
       " ['с', 'тёмный'],\n",
       " ['тёмный', 'рисунок'],\n",
       " ['рисунок', 'тёмный'],\n",
       " ['тёмный', 'полоска'],\n",
       " ['полоска', 'у'],\n",
       " ['у', 'разрез'],\n",
       " ['разрез', 'рот'],\n",
       " ['рот', 'уса'],\n",
       " ['уса', 'почти'],\n",
       " ['почти', 'незаметный'],\n",
       " ['незаметный', 'на'],\n",
       " ['на', 'надклювье'],\n",
       " ['надклювье', 'как'],\n",
       " ['как', 'у'],\n",
       " ['у', 'весь'],\n",
       " ['весь', 'соколов'],\n",
       " ['соколов', 'характерный'],\n",
       " ['характерный', 'зубец'],\n",
       " ['зубец', 'лапа'],\n",
       " ['лапа', 'жёлтый'],\n",
       " ['жёлтый', 'скорость'],\n",
       " ['скорость', 'в'],\n",
       " ['в', 'полёт'],\n",
       " ['полёт', 'высокий'],\n",
       " ['высокий', 'после'],\n",
       " ['после', 'несколько'],\n",
       " ['несколько', 'взмах'],\n",
       " ['взмах', 'птица'],\n",
       " ['птица', 'быстро'],\n",
       " ['быстро', 'нестись'],\n",
       " ['нестись', 'вперёд'],\n",
       " ['вперёд', 'не'],\n",
       " ['не', 'парить'],\n",
       " ['парить', 'сидеть'],\n",
       " ['сидеть', 'кречет'],\n",
       " ['кречет', 'держаться'],\n",
       " ['держаться', 'прямо'],\n",
       " ['прямо', 'кречет'],\n",
       " ['кречет', 'похожий'],\n",
       " ['похожий', 'на'],\n",
       " ['на', 'сапсан'],\n",
       " ['сапсан', 'но'],\n",
       " ['но', 'крупный'],\n",
       " ['крупный', 'и'],\n",
       " ['и', 'иметь'],\n",
       " ['иметь', 'относительно'],\n",
       " ['относительно', 'более'],\n",
       " ['более', 'длинный'],\n",
       " ['длинный', 'хвост'],\n",
       " ['хвост', 'голос'],\n",
       " ['голос', 'также'],\n",
       " ['также', 'похожий'],\n",
       " ['похожий', 'на'],\n",
       " ['на', 'голос'],\n",
       " ['голос', 'сапсан'],\n",
       " ['сапсан', 'но'],\n",
       " ['но', 'грубый'],\n",
       " ['грубый', 'и'],\n",
       " ['и', 'ниже'],\n",
       " ['ниже', 'хриплый'],\n",
       " ['хриплый', 'кьяк'],\n",
       " ['кьяк', 'кьяк'],\n",
       " ['кьяк', 'кьяк'],\n",
       " ['кьяк', 'или'],\n",
       " ['или', 'протяжный'],\n",
       " ['протяжный', 'кейка'],\n",
       " ['кейка', 'кейка'],\n",
       " ['кейка', 'кейка'],\n",
       " ['кейка', 'весной'],\n",
       " ['весной', 'мочь'],\n",
       " ['мочь', 'издавать'],\n",
       " ['издавать', 'довольно'],\n",
       " ['довольно', 'тихий'],\n",
       " ['тихий', 'и'],\n",
       " ['и', 'высокий'],\n",
       " ['высокий', 'трель'],\n",
       " ['трель', 'южный'],\n",
       " ['южный', 'горный'],\n",
       " ['горный', 'подвид'],\n",
       " ['подвид', 'алтайский'],\n",
       " ['алтайский', 'кречет'],\n",
       " ['кречет', 'который'],\n",
       " ['который', 'многие'],\n",
       " ['многие', 'специалист'],\n",
       " ['специалист', 'считать'],\n",
       " ['считать', 'подвид'],\n",
       " ['подвид', 'или'],\n",
       " ['или', 'морфа'],\n",
       " ['морфа', 'балобан'],\n",
       " ['балобан', 'отличаться'],\n",
       " ['отличаться', 'более'],\n",
       " ['более', 'однообразный'],\n",
       " ['однообразный', 'тёмный'],\n",
       " ['тёмный', 'окраска']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams(normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['кречет', 'лата', 'falco'],\n",
       " ['лата', 'falco', 'rusticolus'],\n",
       " ['falco', 'rusticolus', 'птица'],\n",
       " ['rusticolus', 'птица', 'из'],\n",
       " ['птица', 'из', 'отряд'],\n",
       " ['из', 'отряд', 'соколообразный'],\n",
       " ['отряд', 'соколообразный', 'семейство'],\n",
       " ['соколообразный', 'семейство', 'соколиный'],\n",
       " ['семейство', 'соколиный', 'самый'],\n",
       " ['соколиный', 'самый', 'крупный'],\n",
       " ['самый', 'крупный', 'из'],\n",
       " ['крупный', 'из', 'соколов'],\n",
       " ['из', 'соколов', 'масса'],\n",
       " ['соколов', 'масса', 'самец'],\n",
       " ['масса', 'самец', 'чуть'],\n",
       " ['самец', 'чуть', 'большой'],\n",
       " ['чуть', 'большой', '1'],\n",
       " ['большой', '1', 'килограмм'],\n",
       " ['1', 'килограмм', 'самка'],\n",
       " ['килограмм', 'самка', 'до'],\n",
       " ['самка', 'до', '2'],\n",
       " ['до', '2', 'килограмм'],\n",
       " ['2', 'килограмм', 'окраска'],\n",
       " ['килограмм', 'окраска', 'сибирский'],\n",
       " ['окраска', 'сибирский', 'кречет'],\n",
       " ['сибирский', 'кречет', 'светлый'],\n",
       " ['кречет', 'светлый', 'светлый'],\n",
       " ['светлый', 'светлый', 'лапландский'],\n",
       " ['светлый', 'лапландский', 'кречетовый'],\n",
       " ['лапландский', 'кречетовый', 'но'],\n",
       " ['кречетовый', 'но', 'изменчивый'],\n",
       " ['но', 'изменчивый', 'от'],\n",
       " ['изменчивый', 'от', 'буроватый'],\n",
       " ['от', 'буроватый', 'сера'],\n",
       " ['буроватый', 'сера', 'до'],\n",
       " ['сера', 'до', 'почти'],\n",
       " ['до', 'почти', 'бела'],\n",
       " ['почти', 'бела', 'сверху'],\n",
       " ['бела', 'сверху', 'брюшной'],\n",
       " ['сверху', 'брюшной', 'сторона'],\n",
       " ['брюшной', 'сторона', 'беловатый'],\n",
       " ['сторона', 'беловатый', 'с'],\n",
       " ['беловатый', 'с', 'тёмный'],\n",
       " ['с', 'тёмный', 'рисунок'],\n",
       " ['тёмный', 'рисунок', 'тёмный'],\n",
       " ['рисунок', 'тёмный', 'полоска'],\n",
       " ['тёмный', 'полоска', 'у'],\n",
       " ['полоска', 'у', 'разрез'],\n",
       " ['у', 'разрез', 'рот'],\n",
       " ['разрез', 'рот', 'уса'],\n",
       " ['рот', 'уса', 'почти'],\n",
       " ['уса', 'почти', 'незаметный'],\n",
       " ['почти', 'незаметный', 'на'],\n",
       " ['незаметный', 'на', 'надклювье'],\n",
       " ['на', 'надклювье', 'как'],\n",
       " ['надклювье', 'как', 'у'],\n",
       " ['как', 'у', 'весь'],\n",
       " ['у', 'весь', 'соколов'],\n",
       " ['весь', 'соколов', 'характерный'],\n",
       " ['соколов', 'характерный', 'зубец'],\n",
       " ['характерный', 'зубец', 'лапа'],\n",
       " ['зубец', 'лапа', 'жёлтый'],\n",
       " ['лапа', 'жёлтый', 'скорость'],\n",
       " ['жёлтый', 'скорость', 'в'],\n",
       " ['скорость', 'в', 'полёт'],\n",
       " ['в', 'полёт', 'высокий'],\n",
       " ['полёт', 'высокий', 'после'],\n",
       " ['высокий', 'после', 'несколько'],\n",
       " ['после', 'несколько', 'взмах'],\n",
       " ['несколько', 'взмах', 'птица'],\n",
       " ['взмах', 'птица', 'быстро'],\n",
       " ['птица', 'быстро', 'нестись'],\n",
       " ['быстро', 'нестись', 'вперёд'],\n",
       " ['нестись', 'вперёд', 'не'],\n",
       " ['вперёд', 'не', 'парить'],\n",
       " ['не', 'парить', 'сидеть'],\n",
       " ['парить', 'сидеть', 'кречет'],\n",
       " ['сидеть', 'кречет', 'держаться'],\n",
       " ['кречет', 'держаться', 'прямо'],\n",
       " ['держаться', 'прямо', 'кречет'],\n",
       " ['прямо', 'кречет', 'похожий'],\n",
       " ['кречет', 'похожий', 'на'],\n",
       " ['похожий', 'на', 'сапсан'],\n",
       " ['на', 'сапсан', 'но'],\n",
       " ['сапсан', 'но', 'крупный'],\n",
       " ['но', 'крупный', 'и'],\n",
       " ['крупный', 'и', 'иметь'],\n",
       " ['и', 'иметь', 'относительно'],\n",
       " ['иметь', 'относительно', 'более'],\n",
       " ['относительно', 'более', 'длинный'],\n",
       " ['более', 'длинный', 'хвост'],\n",
       " ['длинный', 'хвост', 'голос'],\n",
       " ['хвост', 'голос', 'также'],\n",
       " ['голос', 'также', 'похожий'],\n",
       " ['также', 'похожий', 'на'],\n",
       " ['похожий', 'на', 'голос'],\n",
       " ['на', 'голос', 'сапсан'],\n",
       " ['голос', 'сапсан', 'но'],\n",
       " ['сапсан', 'но', 'грубый'],\n",
       " ['но', 'грубый', 'и'],\n",
       " ['грубый', 'и', 'ниже'],\n",
       " ['и', 'ниже', 'хриплый'],\n",
       " ['ниже', 'хриплый', 'кьяк'],\n",
       " ['хриплый', 'кьяк', 'кьяк'],\n",
       " ['кьяк', 'кьяк', 'кьяк'],\n",
       " ['кьяк', 'кьяк', 'или'],\n",
       " ['кьяк', 'или', 'протяжный'],\n",
       " ['или', 'протяжный', 'кейка'],\n",
       " ['протяжный', 'кейка', 'кейка'],\n",
       " ['кейка', 'кейка', 'кейка'],\n",
       " ['кейка', 'кейка', 'весной'],\n",
       " ['кейка', 'весной', 'мочь'],\n",
       " ['весной', 'мочь', 'издавать'],\n",
       " ['мочь', 'издавать', 'довольно'],\n",
       " ['издавать', 'довольно', 'тихий'],\n",
       " ['довольно', 'тихий', 'и'],\n",
       " ['тихий', 'и', 'высокий'],\n",
       " ['и', 'высокий', 'трель'],\n",
       " ['высокий', 'трель', 'южный'],\n",
       " ['трель', 'южный', 'горный'],\n",
       " ['южный', 'горный', 'подвид'],\n",
       " ['горный', 'подвид', 'алтайский'],\n",
       " ['подвид', 'алтайский', 'кречет'],\n",
       " ['алтайский', 'кречет', 'который'],\n",
       " ['кречет', 'который', 'многие'],\n",
       " ['который', 'многие', 'специалист'],\n",
       " ['многие', 'специалист', 'считать'],\n",
       " ['специалист', 'считать', 'подвид'],\n",
       " ['считать', 'подвид', 'или'],\n",
       " ['подвид', 'или', 'морфа'],\n",
       " ['или', 'морфа', 'балобан'],\n",
       " ['морфа', 'балобан', 'отличаться'],\n",
       " ['балобан', 'отличаться', 'более'],\n",
       " ['отличаться', 'более', 'однообразный'],\n",
       " ['более', 'однообразный', 'тёмный'],\n",
       " ['однообразный', 'тёмный', 'окраска']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams(normalize(text), n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['кречет', 'лата'],\n",
       " ['соколов', 'масса'],\n",
       " ['масса', 'самец'],\n",
       " ['килограмм', 'самка'],\n",
       " ['килограмм', 'окраска'],\n",
       " ['разрез', 'рот'],\n",
       " ['рот', 'уса'],\n",
       " ['зубец', 'лапа'],\n",
       " ['взмах', 'птица'],\n",
       " ['хвост', 'голос'],\n",
       " ['голос', 'сапсан'],\n",
       " ['кьяк', 'кьяк'],\n",
       " ['кьяк', 'кьяк'],\n",
       " ['кейка', 'кейка'],\n",
       " ['кейка', 'кейка'],\n",
       " ['морфа', 'балобан']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams(normalize(text), patterns=[['NOUN', 'NOUN']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем небольшой корпус, который лежит тут же в папке data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"data/ng_1.jsonlines\", encoding='utf-8', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[школа, образовательные стандарты, литература, история, фгос]</td>\n",
       "      <td>Ольга Васильева обещала \"НГ\" не перегружать школьников</td>\n",
       "      <td>https://amp.ng.ru/?p=http://www.ng.ru/education/2018-03-22/8_7195_school.html</td>\n",
       "      <td>В среду состоялось отложенное заседание Совета по федеральным государственным образовательным стандартам (ФГОС) при Министерстве образования и науки РФ. Собрание должно было состояться еще в понедельник, но было перенесено по просьбе членов совета. И вот пришло сообщение, что общественники выразили согласие с позицией министерства. Новые ФГОСы приняты.\\nНа вчерашнем заседании был принят ФГОС по начальной общеобразовательной школе. До 28 марта продлятся косультации по ФГОСам для средней школы.\\nНапомним, что накануне Гильдия словесников разместила открытое письмо на имя министра образования и науки РФ Ольги Васильевой. По мнению авторов письма, новые ФГОСы грубо нарушают права детей, уже проучившихся по существующему стандарту до 6-го класса. Приняв новый стандарт, Министерство образования дает право контролирующим органам ловить детей на незнании большого списка произведений (235 за пять лет обучения). «Это исключает возможность полноценного их освоения, создает риск формального, п...</td>\n",
       "      <td>Глава Минобрнауки считает, что в нездоровом ажиотаже вокруг новых образовательных стандартов виноваты издательства учебной литературы</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        keywords  \\\n",
       "0  [школа, образовательные стандарты, литература, история, фгос]   \n",
       "\n",
       "                                                    title  \\\n",
       "0  Ольга Васильева обещала \"НГ\" не перегружать школьников   \n",
       "\n",
       "                                                                             url  \\\n",
       "0  https://amp.ng.ru/?p=http://www.ng.ru/education/2018-03-22/8_7195_school.html   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   content  \\\n",
       "0  В среду состоялось отложенное заседание Совета по федеральным государственным образовательным стандартам (ФГОС) при Министерстве образования и науки РФ. Собрание должно было состояться еще в понедельник, но было перенесено по просьбе членов совета. И вот пришло сообщение, что общественники выразили согласие с позицией министерства. Новые ФГОСы приняты.\\nНа вчерашнем заседании был принят ФГОС по начальной общеобразовательной школе. До 28 марта продлятся косультации по ФГОСам для средней школы.\\nНапомним, что накануне Гильдия словесников разместила открытое письмо на имя министра образования и науки РФ Ольги Васильевой. По мнению авторов письма, новые ФГОСы грубо нарушают права детей, уже проучившихся по существующему стандарту до 6-го класса. Приняв новый стандарт, Министерство образования дает право контролирующим органам ловить детей на незнании большого списка произведений (235 за пять лет обучения). «Это исключает возможность полноценного их освоения, создает риск формального, п...   \n",
       "\n",
       "                                                                                                                                 summary  \n",
       "0  Глава Минобрнауки считает, что в нездоровом ажиотаже вокруг новых образовательных стандартов виноваты издательства учебной литературы  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем биграммы из первого текста и попробуем просто найти самые частотные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = get_ngrams(normalize(data['content'][0]))\n",
    "c = Counter()\n",
    "for n in bigrams:\n",
    "    c[tuple(n)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ольга', 'васильев'), 6),\n",
       " (('исторический', 'источник'), 6),\n",
       " (('что', 'читать'), 3),\n",
       " (('предметный', 'результат'), 3),\n",
       " (('в', 'прежний'), 3),\n",
       " (('заседание', 'совет'), 2),\n",
       " (('совет', 'по'), 2),\n",
       " (('федеральный', 'государственный'), 2),\n",
       " (('государственный', 'образовательный'), 2),\n",
       " (('образовательный', 'стандарт'), 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно не включать энграммы, которые содержат предлоги, союзы и т.д.\n",
    "Попробуем использовать список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "\n",
    "def get_ngrams_stopwords(tokens, n=2, patterns=None, stoplist=[]):\n",
    "    tokens = list(filter(lambda x: x not in stoplist, tokens))\n",
    "    ngrams = []\n",
    "    for i in range(len(tokens) - (n - 1)):\n",
    "        ngram = tokens[i:i+n]\n",
    "        tags = [m.parse(t)[0].tag.POS for t in ngram]\n",
    "        if patterns is not None:\n",
    "            if tags in patterns:\n",
    "                ngrams.append(tuple(ngram))\n",
    "        else:\n",
    "            ngrams.append(tuple(ngram))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['оно', 'абырвалг']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngrams_stopwords(['я', 'и', 'оно', 'абырвалг'], n=2, stoplist=stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В списке есть сочетания, которые попали в список из-за того, что одно слово очень частотное и вообще встречается много в каких контекстах. Нас скорее интересуют случаи, когда слова в большинстве случаев встречаются вместе. Для этого мы можем придумать какие-нибудь формулы, учитывающие частоты слов по отдельности и общую частоту.\n",
    "\n",
    "Самый простой способ - взять частоту энграммы и поделить на сумму количеств упоминаний слов по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_simple(word_count_a, word_count_b, bigram_count, _):\n",
    "    try:\n",
    "        score = bigram_count / ((word_count_a + word_count_b) - bigram_count)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем функцию, которая будет считать частоты для биграмм и слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(texts, n=2):\n",
    "    word_counter = Counter()\n",
    "    ngram_counter = Counter()\n",
    "    for text in texts:\n",
    "        word_counter.update(text)\n",
    "        ngram_counter.update(get_ngrams_stopwords(text, 2, stoplist=stop))\n",
    "    \n",
    "    return word_counter, ngram_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И функцию, которая считает значение метрики для каждой энграммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bigrams(word_counter, bigram_counter, scorer, threshold=-100000):\n",
    "    ### YOUR CODE HERE\n",
    "    bigram2score = Counter()\n",
    "    for bigram in bigram_counter.keys():\n",
    "        score = scorer(word_counter[bigram[0]], word_counter[bigram[0]], bigram_counter[bigram], len(word_counter))\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    ## если метрика выше порога, добавляем в словарь\n",
    "    return bigram2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [normalize(data['content'][0])]\n",
    "word_counter, bigram_counter = collect_stats(texts)\n",
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('среда', 'состояться'), 1.0),\n",
       " (('отложить', 'заседание'), 1.0),\n",
       " (('федеральный', 'государственный'), 1.0),\n",
       " (('государственный', 'образовательный'), 1.0),\n",
       " (('наука', 'рф'), 1.0),\n",
       " (('собрание', 'должный'), 1.0),\n",
       " (('понедельник', 'перенести'), 1.0),\n",
       " (('перенести', 'просьба'), 1.0),\n",
       " (('просьба', 'член'), 1.0),\n",
       " (('член', 'совет'), 1.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что пошло не так?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_simple_smoothed(word_count_a, word_count_b, bigram_count, _, min_count=2):\n",
    "    try:\n",
    "        score = (bigram_count - min_count) / ((word_count_a + word_count_b) - bigram_count)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_simple_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ольга', 'васильев'), 0.6666666666666666),\n",
       " (('исторический', 'источник'), 0.6666666666666666),\n",
       " (('предметный', 'результат'), 0.2),\n",
       " (('событие', 'явление'), 0.2),\n",
       " (('заседание', 'совет'), 0.0),\n",
       " (('федеральный', 'государственный'), 0.0),\n",
       " (('государственный', 'образовательный'), 0.0),\n",
       " (('образовательный', 'стандарт'), 0.0),\n",
       " (('министерство', 'образование'), 0.0),\n",
       " (('образование', 'наука'), 0.0),\n",
       " (('наука', 'рф'), 0.0),\n",
       " (('новое', 'фгоса'), 0.0),\n",
       " (('вчерашний', 'заседание'), 0.0),\n",
       " (('гильдия', 'словесник'), 0.0),\n",
       " (('открытый', 'письмо'), 0.0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже приличнее. В [статье](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) про word2vec для склейки устойчивых словосочетаний используют такую штуку (стр. 6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_mwe(word_count_a, word_count_b, bigram_count, len_vocab, min_count=2):\n",
    "    try:\n",
    "        score = ((bigram_count - min_count) / (word_count_a * word_count_b)) * len_vocab\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ольга', 'васильев'), 38.77777777777778),\n",
       " (('исторический', 'источник'), 38.77777777777778),\n",
       " (('предметный', 'результат'), 21.8125),\n",
       " (('событие', 'явление'), 21.8125),\n",
       " (('заседание', 'совет'), 0.0),\n",
       " (('федеральный', 'государственный'), 0.0),\n",
       " (('государственный', 'образовательный'), 0.0),\n",
       " (('образовательный', 'стандарт'), 0.0),\n",
       " (('министерство', 'образование'), 0.0),\n",
       " (('образование', 'наука'), 0.0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_mwe)\n",
    "bigram2score.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё одна популярная метрика - Pointwise Mutual Information (PMI, взаимная информация). \n",
    "\n",
    "$$PMI = \\log{\\frac{p(a,b)}{p(a)p(b)}}$$\n",
    "\n",
    "Для её вычисления используются нормализованные частоты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def scorer_pmi(word_count_a, word_count_b, bigram_count, _, corpus_size, minimum_count=2):\n",
    "    score = (((bigram_count - minimum_count) /corpus_size) / ((word_count_a/corpus_size) * (word_count_b/corpus_size)))\n",
    "    if score == 0:\n",
    "        return score\n",
    "    return np.log(score) / -np.log((bigram_count/corpus_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придется переписать функцию, которая применяет метрику к биграммам, потому что теперь мы хотим учитывать размер корпуса, а не словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_bigrams(word_counter, bigram_counter, scorer, threshold=-100000):\n",
    "    bigram2score = Counter()\n",
    "    len_vocab = len(word_counter)\n",
    "    corpus_size = sum(word_counter.values())\n",
    "    for bigram in bigram_counter:\n",
    "        score = scorer(word_counter[bigram[0]], word_counter[bigram[1]], \n",
    "                       bigram_counter[bigram], len_vocab, corpus_size)\n",
    "        if score > threshold:\n",
    "            bigram2score[bigram] = score\n",
    "    return bigram2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('ольга', 'васильев'), 0.9145738272491452),\n",
       " (('исторический', 'источник'), 0.8539629931054739),\n",
       " (('событие', 'явление'), 0.7451443434793612),\n",
       " (('предметный', 'результат'), 0.6177165152190418),\n",
       " (('заседание', 'совет'), 0.0),\n",
       " (('федеральный', 'государственный'), 0.0),\n",
       " (('государственный', 'образовательный'), 0.0),\n",
       " (('образовательный', 'стандарт'), 0.0),\n",
       " (('министерство', 'образование'), 0.0),\n",
       " (('образование', 'наука'), 0.0)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_pmi)\n",
    "bigram2score.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще метрики для выделения коллокаций — это статистические меры/критерии ассоциации/связи. Популярная в статистике мера — [t-test](https://en.wikipedia.org/wiki/Student%27s_t-test) (он же по-русски T-критерий Стьюдента):\n",
    "\n",
    "$$t = \\frac{\\bar{x} - \\mu}{\\sqrt{\\frac{s^2}{n}}}$$\n",
    "\n",
    "где $\\bar{x}$ — наблюдаемое среднее (нормализованная частота биграммы)\n",
    "\n",
    "$\\mu$ — ожидаемое среднее (считаем, что появление каждого слова независимо, то есть произведение вероятностей)\n",
    "\n",
    "$s$ — стандартное отклонение ($s^2$ — дисперсия; \n",
    "выбор слова описывается распределением Бернулли, поэтому $s^2 = p(1-p)$)\n",
    "\n",
    "$n$ — размер выборки (размер корпуса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer_ttest(word_count_a, word_count_b, bigram_count, _, corpus_size, minimum_count=5):\n",
    "    mu = ((word_count_a/corpus_size) * (word_count_b/corpus_size))\n",
    "    x_ = (bigram_count/corpus_size)\n",
    "    score = (x_ - mu) / np.sqrt(x_/corpus_size)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ольга', 'васильев'), 2.4282206567387514),\n",
       " (('исторический', 'источник'), 2.4211309613906087),\n",
       " (('событие', 'явление'), 1.722024464254441),\n",
       " (('предметный', 'результат'), 1.7119981209400046),\n",
       " (('федеральный', 'государственный'), 1.4101203248553726),\n",
       " (('гильдия', 'словесник'), 1.4101203248553726),\n",
       " (('количество', 'лирический'), 1.4101203248553726),\n",
       " (('наука', 'рф'), 1.4080737060965114),\n",
       " (('вчерашний', 'заседание'), 1.4080737060965114),\n",
       " (('год', 'обучение'), 1.4080737060965114)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2score = score_bigrams(word_counter, bigram_counter, scorer_ttest)\n",
    "bigram2score.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё много замечательных метрик, и многие из них реализованы в модуле `nltk.collocations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder2 = BigramCollocationFinder.from_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ольга', 'васильев'),\n",
       " ('исторический', 'источник'),\n",
       " ('гильдия', 'словесник'),\n",
       " ('количество', 'лирический'),\n",
       " ('федеральный', 'государственный'),\n",
       " ('что', 'читать'),\n",
       " ('предметный', 'результат'),\n",
       " ('большой', 'количество'),\n",
       " ('вчерашний', 'заседание'),\n",
       " ('год', 'обучение'),\n",
       " ('наука', 'рф'),\n",
       " ('самый', 'важный'),\n",
       " ('в', 'прежний'),\n",
       " ('лирический', 'произведение'),\n",
       " ('открытый', 'письмо'),\n",
       " ('требование', 'к'),\n",
       " ('заседание', 'совет'),\n",
       " ('государственный', 'образовательный'),\n",
       " ('единый', 'образовательный'),\n",
       " ('новое', 'фгоса')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder2.nbest(bigram_measures.likelihood_ratio, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('15', '20'),\n",
       " ('28', 'март'),\n",
       " ('авторство', 'время'),\n",
       " ('взяться', 'такой'),\n",
       " ('внутренний', 'возраст'),\n",
       " ('возможность', 'полноценный'),\n",
       " ('восприниматься', 'общество'),\n",
       " ('вот', 'пришлый'),\n",
       " ('всегда', 'разный'),\n",
       " ('выразить', 'согласие'),\n",
       " ('говорить', 'детализовать'),\n",
       " ('грубо', 'нарушать'),\n",
       " ('дополнить', 'предложение'),\n",
       " ('доработка', 'действующий'),\n",
       " ('думать', 'любой'),\n",
       " ('душить', 'интеллект'),\n",
       " ('есть', 'стихотворение'),\n",
       " ('жёстко', 'прикрепить'),\n",
       " ('закрепить', 'перечень'),\n",
       " ('замечательный', 'вещь')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder2.nbest(bigram_measures.pmi, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = finder2.score_ngrams(bigram_measures.dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('исторический', 'источник'), 0.8571428571428571),\n",
       " (('большой', 'количество'), 0.8),\n",
       " (('вчерашний', 'заседание'), 0.8),\n",
       " (('год', 'обучение'), 0.8),\n",
       " (('наука', 'рф'), 0.8),\n",
       " (('20', 'конкретный'), 0.6666666666666666),\n",
       " (('235', 'за'), 0.6666666666666666),\n",
       " (('5', '6'), 0.6666666666666666),\n",
       " (('6', 'го'), 0.6666666666666666),\n",
       " (('facebook', 'учитель'), 0.6666666666666666),\n",
       " (('ажиотаж', 'вокруг'), 0.6666666666666666),\n",
       " (('атрибуция', 'текстовый'), 0.6666666666666666),\n",
       " (('большинство', 'вопрос'), 0.6666666666666666),\n",
       " (('весь', 'изменение'), 0.6666666666666666),\n",
       " (('господин', 'волков'), 0.6666666666666666),\n",
       " (('до', '28'), 0.6666666666666666),\n",
       " (('ещё', 'три'), 0.6666666666666666),\n",
       " (('за', 'пять'), 0.6666666666666666),\n",
       " (('заседание', 'совет'), 0.6666666666666666),\n",
       " (('здесь', 'нормативный'), 0.6666666666666666)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([x for x in scores if x[1] != 1.0], key=lambda x: x[1], reverse=True)[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
